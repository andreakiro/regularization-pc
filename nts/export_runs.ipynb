{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import warnings\n",
    "import pickle\n",
    "import wandb\n",
    "import time\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api(timeout=60)\n",
    "entity, project = 'the-real-dl', 'bio-transformers'\n",
    "runs = api.runs(entity + '/' + project) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(wandb_runs, maxrun=None):\n",
    "    \n",
    "    dfs = []\n",
    "    configs = []\n",
    "    summaries = []\n",
    "    count = 0\n",
    "\n",
    "    for i, run in enumerate(runs):\n",
    "        # time.sleep(2) # to avoid 429 Client Error\n",
    "        print(f'Fetching run #{i}', end='\\r')\n",
    "        if maxrun is not None and count == maxrun: break\n",
    "\n",
    "        summary = run.summary\n",
    "        if not 'epoch' in summary.keys(): continue\n",
    "        if run.state == 'running': continue\n",
    "        if run.state == 'crashed': continue\n",
    "        if run.state == 'failed': continue\n",
    "\n",
    "        run_id = run.id\n",
    "        sweep_id = run.sweep.id\n",
    "\n",
    "        config = run.config\n",
    "        run_df = run.history()\n",
    "\n",
    "        config.update({'sweep-id': sweep_id, 'run-id': run_id})\n",
    "        summary.update({'sweep-id': sweep_id, 'run-id': run_id})\n",
    "\n",
    "        l_epochs = []\n",
    "        l_train_loss = []\n",
    "        l_test_loss = []\n",
    "        l_train_energy = []\n",
    "\n",
    "        for e in range(summary['epoch']):\n",
    "            x = run_df[run_df.epoch == e]\n",
    "            if len(x.index) == 0: continue\n",
    "\n",
    "            train_losses = x.train_loss.unique()\n",
    "            test_losses = x.test_loss.unique()\n",
    "\n",
    "            train_loss_no_nan = train_losses[~np.isnan(train_losses)]\n",
    "            test_loss_no_nan = test_losses[~np.isnan(test_losses)]\n",
    "\n",
    "            train_loss = train_loss_no_nan[0] if len(train_loss_no_nan) > 0 else np.nan\n",
    "            test_loss = test_loss_no_nan[0] if len(test_loss_no_nan) > 0 else np.nan\n",
    "\n",
    "            l_epochs.append(e)\n",
    "            l_train_loss.append(train_loss)\n",
    "            l_test_loss.append(test_loss)\n",
    "\n",
    "            if config['training'] == 'pc':\n",
    "                train_energies = x.train_energy.unique()\n",
    "                train_energy_no_nan = train_energies[~np.isnan(train_energies)]\n",
    "                train_energy = train_energy_no_nan[0] if len(train_energy_no_nan) > 0 else np.nan\n",
    "                l_train_energy.append(train_energy)\n",
    "\n",
    "            if config['training'] == 'bp':\n",
    "                run_ids = np.full(len(l_epochs), run_id)\n",
    "                sweep_ids = np.full(len(l_epochs), sweep_id)\n",
    "                data = list(zip(sweep_ids, run_ids, l_epochs, l_train_loss, l_test_loss))\n",
    "                columns = ['sweep-id', 'run-id', 'epoch', 'train_loss', 'test_loss']\n",
    "            else:\n",
    "                run_ids = np.full(len(l_epochs), run_id)\n",
    "                sweep_ids = np.full(len(l_epochs), sweep_id)\n",
    "                data = list(zip(sweep_ids, run_ids, l_epochs, l_train_loss, l_test_loss, l_train_energy))\n",
    "                columns = ['sweep-id', 'run-id', 'epoch', 'train_loss', 'test_loss', 'train_energy']\n",
    "\n",
    "        dfs.append(pd.DataFrame(data, columns=columns))\n",
    "        configs.append(config)\n",
    "        summaries.append(summary)\n",
    "        count += 1\n",
    "\n",
    "\n",
    "    print(f'Fetched {count} runs in {runs.entity}/{runs.project} (max runs: {\"all\" if maxrun is None else maxrun})')\n",
    "    return pd.concat(dfs, axis=0), configs, summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 10 runs in the-real-dl/bio-transformers (max runs: 10)\n"
     ]
    }
   ],
   "source": [
    "#with warnings.catch_warnings():\n",
    "df, configs, summaries = extract(runs, maxrun=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('wandb-runs-df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[(df['sweep-id'] == 'mwg5vjm5') & (df['run-id'] == 'ickzsn8q')].train_loss[5:]\n",
    "test  = df[(df['sweep-id'] == 'mwg5vjm5') & (df['run-id'] == 'ickzsn8q')].test_loss[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train, color='blue')\n",
    "plt.plot(test, color='orange')\n",
    "# plt.yscale('log')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
