# bio-transformers

* Predictive coding Tranformer architecture benchmark
* Deep Learning class FW 2022 - ETH ZÃ¼rich
* Set of useful resources and papers [here](resources.md)

## Get started with our code

We implement three models once with BP and once with PC (click for details)
- Basic [regression model](doc/regression.md) to be trained on a noisy sinus time series
- Basic classification model to be trained on the classic MNIST dataset
- Simple Transformer architecture to be trained on a small language dataset