# Wa&B Sweep
entity: deep-learning-ethz
project: bio-transformers
program: train.py
method: bayes

metric:
  name: test_loss
  goal: minimize

parameters:
  wandb:
    value: online

  model:
    value: reg
  training:
    value: pc
  dataset:
    value: housing
  seed:
    value: 42

  # training hyperparams
  epochs:
    value: 800
  lr:
    values: [0.0001, 0.0005, 0.001, 0.005, 0.01]
  batch-size:
    values: [1, 32, 64, 128] 

  # optimizer hyperparams
  optimizer:
    value: adagrad
  weight_decay:
    values: [0, 0.0001, 0.0005, 0.001]
  
  # PC specific parameters
  init:
    value: forward
  x_optimizer:
    values: [adagrad, adam, momentum, rmsprop]
  clr:
    values: [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.03, 0.05, 0.08, 0.1]
  pc_weight_decay:
    values: [0, 0.0001, 0.0005, 0.001]
  iterations:
    values: [5, 10, 50, 100]
  pc_momentum:
    values: [0, 0.3, 0.6, 0.9]
  pc_gamma:
    values: [0, 0.001, 0.01, 0.1, 0.5] 

command:
  - ${env}
  - python3
  - ${program}
  - ${args}
